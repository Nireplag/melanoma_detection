{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma detection using tranfer learning and image augmentation \n",
    "\n",
    "### Inside this project we will use the feature detection of a VGG16 Neural network trained into the IMAGENET dataset and image augmentaion process to increase the number of cases to be used for treining and testing \n",
    "\n",
    "##### References:\n",
    "\n",
    "> https://www.kaggle.com/amyjang/tensorflow-transfer-learning-melanoma\n",
    "\n",
    "> https://sol.sbc.org.br/index.php/sbcas/article/view/6272/6170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules that will be used into the project \n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to create working director for data\n",
    "\n",
    "def create_directory(source:str, object_list:list):\n",
    "    \"\"\"Check if the directory desired already exist into the provided path and create it otherwise\"\"\"\n",
    "    for obj in object_list:\n",
    "        created_path = os.path.join(source, obj)\n",
    "        if os.path.exists(created_path):\n",
    "            print(\"Directory path \"+ str(created_path)+ \" already exist\")\n",
    "        else: \n",
    "            os.mkdir(created_path)\n",
    "            print(\"Directory \" + str(created_path) + \" created \")\n",
    "\n",
    "\n",
    "# define function to validate if image is not corrupted and split data into test and training sets\n",
    "\n",
    "def split_data(source:str, training:str, testing:str, split_size:float):\n",
    "    \"\"\"\n",
    "    Function to validate if data is not corrupted and \n",
    "    split it into training and test sets. \n",
    "    \"\"\"\n",
    "    data_list = os.listdir(source)\n",
    "    random.seed(10)\n",
    "    train_list = random.sample(data_list, int(len(data_list) * split_size), )\n",
    "    for pic in data_list:\n",
    "        pic_path = os.path.join(source,pic)\n",
    "        if os.path.getsize(pic_path) > 0: # file not empty/corrupted\n",
    "             if pic in train_list:\n",
    "                 training_path = os.path.join(training,pic)\n",
    "                 copyfile(pic_path,training_path)\n",
    "                 training_path = '' # clear path\n",
    "             else:\n",
    "                 testing_path = os.path.join(testing, pic)\n",
    "                 copyfile(pic_path, testing_path)\n",
    "                 testing_path = '' # clear path\n",
    "        pic_path = '' # clear path\n",
    "    print(f\"Dataset cleanse and sorting completed for {source}\")     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define source zip, folders to be used and build directories\n",
    " \n",
    "local_zip = \"./Base.zip\" # path where your zip images are located (global or related to this file)\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r') # configure as read\n",
    "zip_ref.extractall('/tmp') # extract information to temporary \n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./train created \n",
      "Directory ./test created \n",
      "Directory ./train/Positive created \n",
      "Directory ./train/Negative created \n",
      "Directory ./test/Positive created \n",
      "Directory ./test/Negative created \n"
     ]
    }
   ],
   "source": [
    "# create working directories\n",
    "create_directory(\"./\", [\"train\", \"test\"]) #folders for test and train data\n",
    "create_directory(\"./train\", [\"Positive\",\"Negative\"]) # folders for positive and negative scenarios inside train\n",
    "create_directory(\"./test\", [\"Positive\",\"Negative\"]) #folders for positive and negative scenarios inside test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cleanse and sorting completed for /tmp/Base/Positivos\n",
      "Dataset cleanse and sorting completed for /tmp/Base/Negativos\n"
     ]
    }
   ],
   "source": [
    "# split data between test and train structures\n",
    "\n",
    "split_data(\"/tmp/Base/Positivos\", \"./train/Positive\", \"./test/Positive\", 0.8) # split for positive images\n",
    "split_data(\"/tmp/Base/Negativos\", \"./train/Negative\", \"./test/Negative\", 0.8) # split for negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load VGG16 model pre-trained with IMAGENET\n",
    "IMAGE_RESIZE = [256, 256] # define size of image to be fed to model\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(input_shape=(*IMAGE_RESIZE,3),\n",
    "                                                        include_top=False, # do not include layer with outputs\n",
    "                                                        weights='imagenet' # which database weights we want ot import\n",
    "                                                        )\n",
    "base_model.trainable = False # lock base model so it is not trained again\n",
    "\n",
    "base_model.summary() # show base model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative weight: 0.75\n",
      "Positive weight: 1.5\n"
     ]
    }
   ],
   "source": [
    "# define output bias so the imbalance between positive nad negative cases inside training data\n",
    "\n",
    "positive = len(os.listdir(\"./train/Positive\"))\n",
    "negative = len(os.listdir(\"./train/Negative\"))\n",
    "\n",
    "output_bias = np.log([positive/negative]) # define a initial bias to correct the model due sample imbalance\n",
    "\n",
    "# creating weights for the classes - 0:Negative, 1:Positive -> tensorflow will autogenerate and encode labels using  \n",
    "# alphabetical order. \n",
    "\n",
    "train_size = negative + positive\n",
    "weight_0 = (1.0/negative)*(train_size)/2.0\n",
    "weight_1 = (1.0/positive)*(train_size)/2.0\n",
    "\n",
    "weights = {0:weight_0, 1:weight_1} # dictionary to be added into model compilation\n",
    "\n",
    "print(f'Negative weight: {weights[0]}')\n",
    "print(f'Positive weight: {weights[1]}')\n",
    "\n",
    "\n",
    "\n",
    "# Is recommended to make this computation after augmentation since the simetry of methods between positive and negative can not\n",
    "# be garanteed \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add output layers to the model and bias\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model, # add the pre-trained model of VGG16\n",
    "    tf.keras.layers.Flatten(), # transform values from matrix to arrays\n",
    "    tf.keras.layers.Dense(512, activation= 'relu'), \n",
    "    tf.keras.layers.Dropout(0.2), # deactivate random conections of neural model during training to avoid overfitting\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid', bias_initializer = tf.keras.initializers.Constant(output_bias)) # output layer using weight initializer to point class imbalance\n",
    "])\n",
    "\n",
    "METRICS =[ # add metrics to be used to eveluate training\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR')\n",
    "\n",
    "    \n",
    "]\n",
    "model.compile( # generate graph to be trained\n",
    "    optimizer=tf.keras.optimizers.Adam(), # define optimizer function to search for weights\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(), # define loss funtion to be minimized\n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 images belonging to 2 classes.\n",
      "Found 14 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create data generators to configure data to train\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255., # scale values to be into range 0 to 1\n",
    "    rotation_range = 90, # rotate image\n",
    "    horizontal_flip = True, #flip image\n",
    "    vertical_flip = True, # flip image, \n",
    "    zoom_range = 0.3, #allow zoom in the image to create augmentaion \n",
    "    width_shift_range = 0.05, # allow move image in the horizontal  \n",
    "    height_shift_range = 0.05, # allow move image in the vertical  \n",
    "    fill_mode='constant', # fill empty space by move with cval\n",
    "    cval = 0, # define constant value to be used\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input # chnage image from RGB to BGR\n",
    ") \n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255., # scale values to be into range 0 to 1\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input # chnage image from RGB to BGR\n",
    ") \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= \"./train\", # directory of training images\n",
    "    target_size=(256,256), # all images will be rezide to 256X256\n",
    "    class_mode= 'binary', # define label as binary\n",
    "    shuffle=True, # shuffle order of images\n",
    "    seed=10, # set seed tp allow reproduction \n",
    "    batch_size=5 # number of images shown in each step\n",
    "    )\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    directory= \"./test\", # directory of training images\n",
    "    target_size=(256,256), # all images will be rezide to 256X256\n",
    "    class_mode= 'binary', # define label as binary\n",
    "    shuffle=True, # shuffle order of images\n",
    "    seed=10, # set seed tp allow reproduction \n",
    "    batch_size=5 # number of images shown in each step\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7740 - tp: 7.0000 - fp: 10.0000 - tn: 24.0000 - fn: 8.0000 - accuracy: 0.6327 - precision: 0.4118 - recall: 0.4667 - auc: 0.5804 - prc: 0.3391 - val_loss: 0.7280 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4444 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4802\n",
      "Epoch 2/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8348 - tp: 6.0000 - fp: 12.0000 - tn: 21.0000 - fn: 10.0000 - accuracy: 0.5510 - precision: 0.3333 - recall: 0.3750 - auc: 0.4953 - prc: 0.4040 - val_loss: 0.6647 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7619 - val_prc: 0.4284\n",
      "Epoch 3/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8452 - tp: 11.0000 - fp: 16.0000 - tn: 16.0000 - fn: 6.0000 - accuracy: 0.5510 - precision: 0.4074 - recall: 0.6471 - auc: 0.5846 - prc: 0.3794 - val_loss: 0.6887 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.5833 - val_prc: 0.5624\n",
      "Epoch 4/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.8687 - tp: 7.0000 - fp: 18.0000 - tn: 15.0000 - fn: 9.0000 - accuracy: 0.4490 - precision: 0.2800 - recall: 0.4375 - auc: 0.5208 - prc: 0.4408 - val_loss: 1.2834 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 1.0000 - val_auc: 0.5417 - val_prc: 0.6750\n",
      "Epoch 5/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9927 - tp: 8.0000 - fp: 14.0000 - tn: 17.0000 - fn: 10.0000 - accuracy: 0.5102 - precision: 0.3636 - recall: 0.4444 - auc: 0.4462 - prc: 0.3173 - val_loss: 0.9515 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3000 - val_precision: 0.3000 - val_recall: 1.0000 - val_auc: 0.6190 - val_prc: 0.3270\n",
      "Epoch 6/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.8907 - tp: 12.0000 - fp: 23.0000 - tn: 9.0000 - fn: 6.0000 - accuracy: 0.4200 - precision: 0.3429 - recall: 0.6667 - auc: 0.4540 - prc: 0.3151 - val_loss: 0.8454 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 1.0000 - val_auc: 0.3958 - val_prc: 0.3262\n",
      "Epoch 7/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.7877 - tp: 9.0000 - fp: 19.0000 - tn: 15.0000 - fn: 6.0000 - accuracy: 0.4898 - precision: 0.3214 - recall: 0.6000 - auc: 0.5020 - prc: 0.3146 - val_loss: 0.6268 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.3333 - val_recall: 0.5000 - val_auc: 0.8750 - val_prc: 0.7123\n",
      "Epoch 8/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7378 - tp: 6.0000 - fp: 4.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6939 - precision: 0.6000 - recall: 0.3529 - auc: 0.6425 - prc: 0.4630 - val_loss: 0.6225 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.9048 - val_prc: 0.8008\n",
      "Epoch 9/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6889 - tp: 7.0000 - fp: 10.0000 - tn: 22.0000 - fn: 10.0000 - accuracy: 0.5918 - precision: 0.4118 - recall: 0.4118 - auc: 0.5790 - prc: 0.4617 - val_loss: 0.6528 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 5.0000 - val_fn: 2.0000 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.5000 - val_auc: 0.6667 - val_prc: 0.5062\n",
      "Epoch 10/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6833 - tp: 10.0000 - fp: 11.0000 - tn: 20.0000 - fn: 8.0000 - accuracy: 0.6122 - precision: 0.4762 - recall: 0.5556 - auc: 0.6407 - prc: 0.4644 - val_loss: 0.6963 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.4000 - val_precision: 0.3750 - val_recall: 0.7500 - val_auc: 0.6250 - val_prc: 0.5974\n",
      "Epoch 11/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6247 - tp: 16.0000 - fp: 19.0000 - tn: 13.0000 - fn: 1.0000 - accuracy: 0.5918 - precision: 0.4571 - recall: 0.9412 - auc: 0.7169 - prc: 0.5761 - val_loss: 0.8565 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3000 - val_precision: 0.3000 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4112\n",
      "Epoch 12/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6916 - tp: 14.0000 - fp: 15.0000 - tn: 17.0000 - fn: 3.0000 - accuracy: 0.6327 - precision: 0.4828 - recall: 0.8235 - auc: 0.6011 - prc: 0.3663 - val_loss: 0.5919 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6190 - val_prc: 0.3546\n",
      "Epoch 13/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7281 - tp: 10.0000 - fp: 12.0000 - tn: 20.0000 - fn: 7.0000 - accuracy: 0.6122 - precision: 0.4545 - recall: 0.5882 - auc: 0.5947 - prc: 0.4090 - val_loss: 0.6730 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.8000 - val_auc: 0.7000 - val_prc: 0.7302\n",
      "Epoch 14/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6082 - tp: 10.0000 - fp: 14.0000 - tn: 21.0000 - fn: 4.0000 - accuracy: 0.6327 - precision: 0.4167 - recall: 0.7143 - auc: 0.6939 - prc: 0.4476 - val_loss: 0.6471 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.5000 - val_auc: 0.6667 - val_prc: 0.7160\n",
      "Epoch 15/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6496 - tp: 4.0000 - fp: 4.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6735 - precision: 0.5000 - recall: 0.2500 - auc: 0.7282 - prc: 0.5640 - val_loss: 0.6360 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.5000 - val_precision: 0.2500 - val_recall: 0.3333 - val_auc: 0.5714 - val_prc: 0.5413\n",
      "Epoch 16/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5912 - tp: 13.0000 - fp: 15.0000 - tn: 18.0000 - fn: 3.0000 - accuracy: 0.6327 - precision: 0.4643 - recall: 0.8125 - auc: 0.7699 - prc: 0.6273 - val_loss: 0.5891 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
      "Epoch 17/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6541 - tp: 10.0000 - fp: 11.0000 - tn: 21.0000 - fn: 7.0000 - accuracy: 0.6327 - precision: 0.4762 - recall: 0.5882 - auc: 0.6710 - prc: 0.5233 - val_loss: 0.6217 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.6000 - val_precision: 0.5000 - val_recall: 0.7500 - val_auc: 0.6667 - val_prc: 0.6284\n",
      "Epoch 18/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5939 - tp: 12.0000 - fp: 8.0000 - tn: 24.0000 - fn: 5.0000 - accuracy: 0.7347 - precision: 0.6000 - recall: 0.7059 - auc: 0.7693 - prc: 0.5948 - val_loss: 0.6341 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.7708 - val_prc: 0.7382\n",
      "Epoch 19/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5857 - tp: 14.0000 - fp: 11.0000 - tn: 22.0000 - fn: 2.0000 - accuracy: 0.7347 - precision: 0.5600 - recall: 0.8750 - auc: 0.7794 - prc: 0.5790 - val_loss: 0.5974 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.8542 - val_prc: 0.8241\n",
      "Epoch 20/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6949 - tp: 11.0000 - fp: 14.0000 - tn: 18.0000 - fn: 6.0000 - accuracy: 0.5918 - precision: 0.4400 - recall: 0.6471 - auc: 0.6020 - prc: 0.3809 - val_loss: 0.7803 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3000 - val_precision: 0.3333 - val_recall: 0.7500 - val_auc: 0.6875 - val_prc: 0.7489\n",
      "Epoch 21/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6082 - tp: 10.0000 - fp: 13.0000 - tn: 21.0000 - fn: 5.0000 - accuracy: 0.6327 - precision: 0.4348 - recall: 0.6667 - auc: 0.7039 - prc: 0.6030 - val_loss: 0.6344 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 0.7500 - val_auc: 0.8333 - val_prc: 0.8665\n",
      "Epoch 22/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6013 - tp: 10.0000 - fp: 3.0000 - tn: 29.0000 - fn: 7.0000 - accuracy: 0.7959 - precision: 0.7692 - recall: 0.5882 - auc: 0.7886 - prc: 0.6843 - val_loss: 0.6459 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.8000 - val_auc: 0.7000 - val_prc: 0.7302\n",
      "Epoch 23/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5968 - tp: 12.0000 - fp: 12.0000 - tn: 21.0000 - fn: 4.0000 - accuracy: 0.6735 - precision: 0.5000 - recall: 0.7500 - auc: 0.7519 - prc: 0.6628 - val_loss: 0.7015 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6000 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.8125 - val_prc: 0.3657\n",
      "Epoch 24/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5719 - tp: 12.0000 - fp: 6.0000 - tn: 25.0000 - fn: 6.0000 - accuracy: 0.7551 - precision: 0.6667 - recall: 0.6667 - auc: 0.7841 - prc: 0.6998 - val_loss: 0.6192 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.7083 - val_prc: 0.7412\n",
      "Epoch 25/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5457 - tp: 14.0000 - fp: 11.0000 - tn: 21.0000 - fn: 3.0000 - accuracy: 0.7143 - precision: 0.5600 - recall: 0.8235 - auc: 0.8153 - prc: 0.6920 - val_loss: 0.7138 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.2857 - val_recall: 1.0000 - val_auc: 0.5938 - val_prc: 0.2121\n",
      "Epoch 26/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6442 - tp: 14.0000 - fp: 20.0000 - tn: 13.0000 - fn: 2.0000 - accuracy: 0.5510 - precision: 0.4118 - recall: 0.8750 - auc: 0.7045 - prc: 0.5791 - val_loss: 0.5846 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8571 - val_prc: 0.8177\n",
      "Epoch 27/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5140 - tp: 9.0000 - fp: 6.0000 - tn: 28.0000 - fn: 6.0000 - accuracy: 0.7551 - precision: 0.6000 - recall: 0.6000 - auc: 0.8412 - prc: 0.7666 - val_loss: 0.5478 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.3333 - val_recall: 0.5000 - val_auc: 0.7500 - val_prc: 0.3069\n",
      "Epoch 28/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4670 - tp: 14.0000 - fp: 8.0000 - tn: 24.0000 - fn: 3.0000 - accuracy: 0.7755 - precision: 0.6364 - recall: 0.8235 - auc: 0.8943 - prc: 0.8008 - val_loss: 0.6617 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7000 - val_precision: 0.5714 - val_recall: 1.0000 - val_auc: 0.7500 - val_prc: 0.7476\n",
      "Epoch 29/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5585 - tp: 12.0000 - fp: 14.0000 - tn: 20.0000 - fn: 3.0000 - accuracy: 0.6531 - precision: 0.4615 - recall: 0.8000 - auc: 0.7951 - prc: 0.6345 - val_loss: 0.6484 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.6667 - val_prc: 0.5062\n",
      "Epoch 30/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5629 - tp: 12.0000 - fp: 12.0000 - tn: 22.0000 - fn: 3.0000 - accuracy: 0.6939 - precision: 0.5000 - recall: 0.8000 - auc: 0.8098 - prc: 0.5616 - val_loss: 0.5715 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 7.0000 - val_fn: 2.0000 - val_accuracy: 0.8000 - val_precision: 1.0000 - val_recall: 0.3333 - val_auc: 0.6905 - val_prc: 0.6353\n",
      "Epoch 31/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7820 - tp: 7.0000 - fp: 8.0000 - tn: 25.0000 - fn: 10.0000 - accuracy: 0.6400 - precision: 0.4667 - recall: 0.4118 - auc: 0.6845 - prc: 0.4230 - val_loss: 0.6162 - val_tp: 4.0000 - val_fp: 1.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8000 - val_prc: 0.6416\n",
      "Epoch 32/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7141 - tp: 13.0000 - fp: 14.0000 - tn: 18.0000 - fn: 4.0000 - accuracy: 0.6327 - precision: 0.4815 - recall: 0.7647 - auc: 0.7325 - prc: 0.5291 - val_loss: 0.5658 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.7000 - val_precision: 0.7500 - val_recall: 0.6000 - val_auc: 0.8000 - val_prc: 0.7551\n",
      "Epoch 33/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6137 - tp: 11.0000 - fp: 9.0000 - tn: 22.0000 - fn: 7.0000 - accuracy: 0.6735 - precision: 0.5500 - recall: 0.6111 - auc: 0.7115 - prc: 0.5728 - val_loss: 0.6087 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.8571 - val_prc: 0.7161\n",
      "Epoch 34/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4252 - tp: 14.0000 - fp: 6.0000 - tn: 26.0000 - fn: 3.0000 - accuracy: 0.8163 - precision: 0.7000 - recall: 0.8235 - auc: 0.9173 - prc: 0.8719 - val_loss: 0.4869 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.9167 - val_prc: 0.9088\n",
      "Epoch 35/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6672 - tp: 10.0000 - fp: 13.0000 - tn: 20.0000 - fn: 6.0000 - accuracy: 0.6122 - precision: 0.4348 - recall: 0.6250 - auc: 0.6913 - prc: 0.5214 - val_loss: 0.5924 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.7000 - val_precision: 0.7500 - val_recall: 0.6000 - val_auc: 0.7600 - val_prc: 0.8036\n",
      "Epoch 36/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4619 - tp: 13.0000 - fp: 6.0000 - tn: 27.0000 - fn: 4.0000 - accuracy: 0.8000 - precision: 0.6842 - recall: 0.7647 - auc: 0.8788 - prc: 0.8253 - val_loss: 0.5924 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
      "Epoch 37/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5423 - tp: 10.0000 - fp: 7.0000 - tn: 27.0000 - fn: 5.0000 - accuracy: 0.7551 - precision: 0.5882 - recall: 0.6667 - auc: 0.7873 - prc: 0.5968 - val_loss: 0.7705 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 0.7500 - val_auc: 0.7083 - val_prc: 0.7297\n",
      "Epoch 38/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4785 - tp: 14.0000 - fp: 13.0000 - tn: 21.0000 - fn: 1.0000 - accuracy: 0.7143 - precision: 0.5185 - recall: 0.9333 - auc: 0.8765 - prc: 0.6610 - val_loss: 0.5535 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.8333 - val_prc: 0.7973\n",
      "Epoch 39/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5100 - tp: 14.0000 - fp: 11.0000 - tn: 21.0000 - fn: 3.0000 - accuracy: 0.7143 - precision: 0.5600 - recall: 0.8235 - auc: 0.8419 - prc: 0.7858 - val_loss: 0.6883 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 5.0000 - val_fn: 2.0000 - val_accuracy: 0.6000 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.4762 - val_prc: 0.5111\n",
      "Epoch 40/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6732 - tp: 7.0000 - fp: 12.0000 - tn: 22.0000 - fn: 8.0000 - accuracy: 0.5918 - precision: 0.3684 - recall: 0.4667 - auc: 0.6431 - prc: 0.5550 - val_loss: 0.4847 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.8750 - val_prc: 0.8369\n",
      "Epoch 41/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4590 - tp: 14.0000 - fp: 7.0000 - tn: 26.0000 - fn: 3.0000 - accuracy: 0.8000 - precision: 0.6667 - recall: 0.8235 - auc: 0.8806 - prc: 0.8410 - val_loss: 0.4288 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.6667 - val_auc: 0.8571 - val_prc: 0.8177\n",
      "Epoch 42/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5966 - tp: 11.0000 - fp: 10.0000 - tn: 22.0000 - fn: 6.0000 - accuracy: 0.6735 - precision: 0.5238 - recall: 0.6471 - auc: 0.7436 - prc: 0.6309 - val_loss: 0.8328 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 0.7500 - val_auc: 0.5833 - val_prc: 0.5865\n",
      "Epoch 43/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5198 - tp: 12.0000 - fp: 9.0000 - tn: 24.0000 - fn: 4.0000 - accuracy: 0.7347 - precision: 0.5714 - recall: 0.7500 - auc: 0.8134 - prc: 0.6023 - val_loss: 0.5362 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7619 - val_prc: 0.4515\n",
      "Epoch 44/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5351 - tp: 12.0000 - fp: 7.0000 - tn: 25.0000 - fn: 5.0000 - accuracy: 0.7551 - precision: 0.6316 - recall: 0.7059 - auc: 0.8189 - prc: 0.7652 - val_loss: 0.4631 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.9048 - val_prc: 0.7690\n",
      "Epoch 45/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4529 - tp: 14.0000 - fp: 11.0000 - tn: 22.0000 - fn: 2.0000 - accuracy: 0.7347 - precision: 0.5600 - recall: 0.8750 - auc: 0.8665 - prc: 0.7555 - val_loss: 0.7487 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.7619 - val_prc: 0.6593\n",
      "Epoch 46/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4417 - tp: 15.0000 - fp: 10.0000 - tn: 22.0000 - fn: 2.0000 - accuracy: 0.7551 - precision: 0.6000 - recall: 0.8824 - auc: 0.8704 - prc: 0.7369 - val_loss: 0.5478 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.8125 - val_prc: 0.7409\n",
      "Epoch 47/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4667 - tp: 12.0000 - fp: 6.0000 - tn: 26.0000 - fn: 5.0000 - accuracy: 0.7755 - precision: 0.6667 - recall: 0.7059 - auc: 0.8704 - prc: 0.7957 - val_loss: 0.6289 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.6000 - val_precision: 0.5714 - val_recall: 0.8000 - val_auc: 0.8000 - val_prc: 0.8470\n",
      "Epoch 48/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4128 - tp: 13.0000 - fp: 9.0000 - tn: 25.0000 - fn: 2.0000 - accuracy: 0.7755 - precision: 0.5909 - recall: 0.8667 - auc: 0.9020 - prc: 0.8281 - val_loss: 0.5102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6875 - val_prc: 0.6146\n",
      "Epoch 49/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3860 - tp: 12.0000 - fp: 3.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8400 - precision: 0.8000 - recall: 0.7059 - auc: 0.9242 - prc: 0.8655 - val_loss: 1.0393 - val_tp: 2.0000 - val_fp: 6.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4000 - val_precision: 0.2500 - val_recall: 1.0000 - val_auc: 0.8750 - val_prc: 0.4507\n",
      "Epoch 50/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5159 - tp: 10.0000 - fp: 12.0000 - tn: 23.0000 - fn: 4.0000 - accuracy: 0.6735 - precision: 0.4545 - recall: 0.7143 - auc: 0.8184 - prc: 0.6465 - val_loss: 0.6791 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.4000 - val_auc: 0.6000 - val_prc: 0.6285\n",
      "Epoch 51/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4679 - tp: 14.0000 - fp: 8.0000 - tn: 24.0000 - fn: 4.0000 - accuracy: 0.7600 - precision: 0.6364 - recall: 0.7778 - auc: 0.8602 - prc: 0.7919 - val_loss: 0.9013 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.3716\n",
      "Epoch 52/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4347 - tp: 15.0000 - fp: 13.0000 - tn: 20.0000 - fn: 1.0000 - accuracy: 0.7143 - precision: 0.5357 - recall: 0.9375 - auc: 0.8987 - prc: 0.8420 - val_loss: 0.4670 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 7.0000 - val_fn: 2.0000 - val_accuracy: 0.8000 - val_precision: 1.0000 - val_recall: 0.3333 - val_auc: 0.7857 - val_prc: 0.6701\n",
      "Epoch 53/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4413 - tp: 12.0000 - fp: 7.0000 - tn: 26.0000 - fn: 4.0000 - accuracy: 0.7755 - precision: 0.6316 - recall: 0.7500 - auc: 0.8778 - prc: 0.7527 - val_loss: 0.4096 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
      "Epoch 54/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3959 - tp: 11.0000 - fp: 5.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8367 - precision: 0.6875 - recall: 0.7857 - auc: 0.8949 - prc: 0.7972 - val_loss: 0.4497 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.8095 - val_prc: 0.4850\n",
      "Epoch 55/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4897 - tp: 12.0000 - fp: 10.0000 - tn: 23.0000 - fn: 4.0000 - accuracy: 0.7143 - precision: 0.5455 - recall: 0.7500 - auc: 0.8419 - prc: 0.7950 - val_loss: 0.5967 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7000 - val_precision: 0.5714 - val_recall: 1.0000 - val_auc: 0.9167 - val_prc: 0.9088\n",
      "Epoch 56/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4690 - tp: 13.0000 - fp: 4.0000 - tn: 28.0000 - fn: 5.0000 - accuracy: 0.8200 - precision: 0.7647 - recall: 0.7222 - auc: 0.8715 - prc: 0.8072 - val_loss: 0.6236 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.7917 - val_prc: 0.7945\n",
      "Epoch 57/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4119 - tp: 15.0000 - fp: 9.0000 - tn: 23.0000 - fn: 2.0000 - accuracy: 0.7755 - precision: 0.6250 - recall: 0.8824 - auc: 0.9026 - prc: 0.8530 - val_loss: 0.5654 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.7619 - val_prc: 0.4284\n",
      "Epoch 58/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3495 - tp: 14.0000 - fp: 4.0000 - tn: 29.0000 - fn: 2.0000 - accuracy: 0.8776 - precision: 0.7778 - recall: 0.8750 - auc: 0.9290 - prc: 0.8934 - val_loss: 0.8916 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4000 - val_precision: 0.2857 - val_recall: 0.6667 - val_auc: 0.6190 - val_prc: 0.6190\n",
      "Epoch 59/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3145 - tp: 14.0000 - fp: 6.0000 - tn: 27.0000 - fn: 2.0000 - accuracy: 0.8367 - precision: 0.7000 - recall: 0.8750 - auc: 0.9545 - prc: 0.9298 - val_loss: 0.6295 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7143 - val_prc: 0.4283\n",
      "Epoch 60/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3683 - tp: 15.0000 - fp: 6.0000 - tn: 26.0000 - fn: 2.0000 - accuracy: 0.8367 - precision: 0.7143 - recall: 0.8824 - auc: 0.9127 - prc: 0.8524 - val_loss: 0.7683 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.5714 - val_prc: 0.3416\n",
      "Epoch 61/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2616 - tp: 14.0000 - fp: 1.0000 - tn: 32.0000 - fn: 2.0000 - accuracy: 0.9388 - precision: 0.9333 - recall: 0.8750 - auc: 0.9735 - prc: 0.9531 - val_loss: 0.6389 - val_tp: 5.0000 - val_fp: 3.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7000 - val_precision: 0.6250 - val_recall: 1.0000 - val_auc: 0.7600 - val_prc: 0.7366\n",
      "Epoch 62/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6945 - tp: 11.0000 - fp: 10.0000 - tn: 23.0000 - fn: 5.0000 - accuracy: 0.6939 - precision: 0.5238 - recall: 0.6875 - auc: 0.7472 - prc: 0.6051 - val_loss: 0.5477 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.8000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.6250 - val_prc: 0.2680\n",
      "Epoch 63/70\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4395 - tp: 13.0000 - fp: 10.0000 - tn: 23.0000 - fn: 3.0000 - accuracy: 0.7347 - precision: 0.5652 - recall: 0.8125 - auc: 0.8892 - prc: 0.8658 - val_loss: 0.8092 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.6000 - val_precision: 0.5714 - val_recall: 0.8000 - val_auc: 0.7400 - val_prc: 0.7218\n",
      "Epoch 64/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4924 - tp: 12.0000 - fp: 9.0000 - tn: 23.0000 - fn: 5.0000 - accuracy: 0.7143 - precision: 0.5714 - recall: 0.7059 - auc: 0.8373 - prc: 0.7042 - val_loss: 0.5983 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 5.0000 - val_fn: 2.0000 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.5000 - val_auc: 0.7500 - val_prc: 0.6932\n",
      "Epoch 65/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4107 - tp: 13.0000 - fp: 10.0000 - tn: 22.0000 - fn: 4.0000 - accuracy: 0.7143 - precision: 0.5652 - recall: 0.7647 - auc: 0.8888 - prc: 0.8543 - val_loss: 0.4392 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8000 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 0.9167 - val_prc: 0.9088\n",
      "Epoch 66/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3580 - tp: 14.0000 - fp: 3.0000 - tn: 29.0000 - fn: 3.0000 - accuracy: 0.8776 - precision: 0.8235 - recall: 0.8235 - auc: 0.9301 - prc: 0.8987 - val_loss: 0.7191 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.5000 - val_precision: 0.2500 - val_recall: 0.3333 - val_auc: 0.6190 - val_prc: 0.5543\n",
      "Epoch 67/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3315 - tp: 16.0000 - fp: 8.0000 - tn: 25.0000 - fn: 0.0000e+00 - accuracy: 0.8367 - precision: 0.6667 - recall: 1.0000 - auc: 0.9517 - prc: 0.8858 - val_loss: 0.3447 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9000 - val_precision: 0.7500 - val_recall: 1.0000 - val_auc: 0.9524 - val_prc: 0.9041\n",
      "Epoch 68/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3100 - tp: 12.0000 - fp: 5.0000 - tn: 29.0000 - fn: 3.0000 - accuracy: 0.8367 - precision: 0.7059 - recall: 0.8000 - auc: 0.9422 - prc: 0.8773 - val_loss: 0.7829 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.7500 - val_auc: 0.6250 - val_prc: 0.4954\n",
      "Epoch 69/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2055 - tp: 16.0000 - fp: 5.0000 - tn: 28.0000 - fn: 0.0000e+00 - accuracy: 0.8980 - precision: 0.7619 - recall: 1.0000 - auc: 0.9820 - prc: 0.9650 - val_loss: 0.6803 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 5.0000 - val_fn: 2.0000 - val_accuracy: 0.6000 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.7143 - val_prc: 0.5945\n",
      "Epoch 70/70\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4516 - tp: 13.0000 - fp: 3.0000 - tn: 28.0000 - fn: 5.0000 - accuracy: 0.8367 - precision: 0.8125 - recall: 0.7222 - auc: 0.8978 - prc: 0.8390 - val_loss: 1.3905 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 1.0000 - val_auc: 0.5800 - val_prc: 0.5392\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"melanoma_model.h5\",\n",
    "                                                    monitor= 'val_precision',\n",
    "                                                    save_best_only=True) # save best model based on the validation value of the precision\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator, # generator of images based on the original ones (augmentation)\n",
    "      steps_per_epoch=10,  # number of image groups shown \n",
    "      epochs=70, # number of repetions of training\n",
    "      validation_data=test_generator, # gererator with validation data \n",
    "      validation_steps= 2, # number of image groups shown in validation \n",
    "      shuffle=True, # shuffle information to better learning of pattern in training\n",
    "      callbacks=[checkpoint_cb], # insert callback to save best model\n",
    "      class_weight= weights # add class weights to aid avoid issues with class imbalance (control>>melanoma samples)\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 774ms/step - loss: 0.5601 - tp: 1.0000 - fp: 0.0000e+00 - tn: 9.0000 - fn: 4.0000 - accuracy: 0.7143 - precision: 1.0000 - recall: 0.2000 - auc: 0.7889 - prc: 0.8125                \n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"melanoma_model.h5\") # load values of best model from file saved during training\n",
    "validation = model.evaluate(test_generator, return_dict=True) # evaluate model with test data to have access to values\n",
    "tp = validation['tp'] # access true positive \n",
    "fp = validation['fp'] # access false positive\n",
    "tn = validation['tn'] # access true negative\n",
    "fn = validation['fn'] # access false negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric          Value\n",
      "-----------  --------\n",
      "Accuracy     0.714286\n",
      "Precision    1\n",
      "Recall       0.2\n",
      "Specificity  1\n",
      "F1 score     0.333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics based on model evaluation data \n",
    "\n",
    "# accuracy: total amount of correct prediction over the total of predictions\n",
    "acc = (tp+tn)/(tp+fp+fn+tn) \n",
    "\n",
    "# precision: correct predicted positive observation over the total of predicted positive observations\n",
    "try: # cannot devide 0 by 0\n",
    "    prec = tp/(tp+fp) \n",
    "except:\n",
    "    prec = 0\n",
    "\n",
    "# recall/sensitivity: correct predicted positive observations over all the positive class(TP+FN)\n",
    "try: # cannot devide 0 by 0\n",
    "    rec = tp/(tp+fn) \n",
    "except:\n",
    "    rec = 0\n",
    "\n",
    "# specificity: correct predicted negative observations over all the negatives (tn+fp)\n",
    "try: # cannot devide 0 by 0\n",
    "    spec = tn/(tn+fp)\n",
    "except:\n",
    "    spec = 0\n",
    "\n",
    "# F1 score: weighted average of precision and recall\n",
    "try: # cannot devide 0 by 0\n",
    "    f1 = 2*(rec*prec)/(rec+prec)\n",
    "except:\n",
    "    f1 = 0\n",
    "\n",
    "# print metrics into tabular form\n",
    "metric = [['Accuracy', acc],['Precision', prec],['Recall', rec],['Specificity', spec],['F1 score', f1]]\n",
    "print(tabulate(metric, headers=['Metric', 'Value']))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e81a6b18c44c9783d940c25134ccc1dd9409bbb831afc04c6a2fd47715ab4d7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
