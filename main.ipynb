{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma detection using tranfer learning and image augmentation \n",
    "\n",
    "### Inside this project we will use the feature detection of a VGG16 Neural network trained into the IMAGENET dataset and image augmentaion process to increase the number of cases to be used for treining and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nireplag/anaconda3/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "# Import modules that will be used into the project \n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from skimage import io\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to create working director for data\n",
    "\n",
    "def create_directory(source:str, object_list:list):\n",
    "    \"\"\"Check if the directory desired already exist into the provided path and create it otherwise\"\"\"\n",
    "    for obj in object_list:\n",
    "        created_path = os.path.join(source, obj)\n",
    "        if os.path.exists(created_path):\n",
    "            print(\"Directory path \"+ str(created_path)+ \" already exist\")\n",
    "        else: \n",
    "            os.mkdir(created_path)\n",
    "            print(\"Directory \" + str(created_path) + \" created \")\n",
    "\n",
    "\n",
    "# define function to validate if image is not corrupted and split data into test and training sets\n",
    "\n",
    "def split_data(source:str, training:str, testing:str, split_size:float):\n",
    "    \"\"\"\n",
    "    Function to validate if data is not corrupted and \n",
    "    split it into training and test sets. \n",
    "    \"\"\"\n",
    "    data_list = os.listdir(source)\n",
    "    train_list = random.sample(data_list, int(len(data_list) * split_size))\n",
    "    for pic in data_list:\n",
    "        pic_path = os.path.join(source,pic)\n",
    "        if os.path.getsize(pic_path) > 0: # file not empty/corrupted\n",
    "             if pic in train_list:\n",
    "                 training_path = os.path.join(training,pic)\n",
    "                 copyfile(pic_path,training_path)\n",
    "                 training_path = '' # clear path\n",
    "             else:\n",
    "                 testing_path = os.path.join(testing, pic)\n",
    "                 copyfile(pic_path, testing_path)\n",
    "                 testing_path = '' # clear path\n",
    "        pic_path = '' # clear path\n",
    "    print(\"Dataset cleanse and sorting completed\")\n",
    "\n",
    "\n",
    "# define function to make data augmentaion and save files into directory with specific tag and ID\n",
    "\n",
    "def img_augment(source:str, methods:list = [\"flipud\", \"fliplr\", \"noise\"], tag:str = \"aug\"):\n",
    "    \"\"\"\n",
    "    Function will use skimage and Numpy package to generate new images based of prebuilt functions\n",
    "    to increase volumn of data. \n",
    "    methods: functions from skimage to be used [\"flipud\", \"fliplr\", \"noise\"]\n",
    "    tag: added string to the end of original image\n",
    "    \"\"\"\n",
    "    counter = 0 # init a counter to add to end of each image\n",
    "    data_list = os.listdir(source)\n",
    "    for pic in data_list:\n",
    "        pic_path = os.path.join(source,pic)\n",
    "        img = io.imread(pic_path)\n",
    "        if \"flipud\" in methods:\n",
    "            aug = np.flipud(img)\n",
    "            counter = counter + 1\n",
    "            img_name = str(tag) + \"_\" + str(counter) + \"_\" + str(pic) \n",
    "            io.imsave(os.path.join(source, img_name), aug)\n",
    "            aug = []\n",
    "            img_name = '' # clear string \n",
    "        elif \"fliplr\" in methods:\n",
    "            aug = np.fliplr(img)\n",
    "            counter = counter + 1\n",
    "            img_name = str(tag) + \"_\" + str(counter) + \"_\" + str(pic) \n",
    "            io.imsave(os.path.join(source, img_name), aug)\n",
    "            aug = []\n",
    "            img_name = '' # clear string\n",
    "        elif \"noise\" in methods:\n",
    "            aug = random_noise(img)\n",
    "            counter = counter + 1\n",
    "            img_name = str(tag) + \"_\" + str(counter) + \"_\" + str(pic) \n",
    "            io.imsave(os.path.join(source, img_name), aug)\n",
    "            aug = []\n",
    "            img_name = '' # clear string \n",
    "        pic_path = '' # clear path\n",
    "        img = []\n",
    "    print(f\"Data Augmentation completed fro folder {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e81a6b18c44c9783d940c25134ccc1dd9409bbb831afc04c6a2fd47715ab4d7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
